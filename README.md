# llm

* [PEFT LoRA Explained in Detail - Fine-Tune your LLM on your local GPU](https://www.youtube.com/watch?v=YVU5wAA6Txo)
* [Boost Fine-Tuning Performance of LLM: Optimal Architecture w/ PEFT LoRA Adapter-Tuning on Your GPU](https://www.youtube.com/watch?v=A-a-l_sFtYM)

## ##
* [Fine Tune Large Language Model (LLM) on a Custom Dataset with QLoRA](https://dassum.medium.com/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07)  





## Pytorch ##

* [[Pytorch] Distributed package 를 이용한 분산학습으로 Multi-GPU 효율적으로 사용하기](https://csm-kr.tistory.com/47)
* [torchvision의 transform으로 이미지 정규화하기](https://teddylee777.github.io/pytorch/torchvision-transform/#google_vignette)
* [Python Ray 사용법 - Python 병렬처리, 분산처리](https://zzsza.github.io/mlops/2021/01/03/python-ray/)
* [Pytorch - torch.size(0)](https://noanomal.tistory.com/6)
* [Numpy Tril()](https://runebook.dev/ko/docs/numpy/reference/generated/numpy.tril)
* [pytorch로 구현하는 Transformer](https://cpm0722.github.io/pytorch-implementation/transformer)   ** 쉽게 설명한 글이다.
  
## 참고자료 ##

* [Pytorch 딥러닝 입문](https://wikidocs.net/book/2788)
