



## 참고자료 ##

* [pytorch FSDP](https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html?utm_source=distr_landing&utm_medium=FSDP_getting_started)
* [Writing Distributed Applications with PyTorch](https://pytorch.org/tutorials/intermediate/dist_tuto.html)
* [다수의 GPU 중 원하는 GPU 타겟팅하기](https://wonder-j.tistory.com/15)
* [processing time 정확히 측정하기 - torch.cuda.synchronize()](https://kalelpark.tistory.com/136)
* [Adatdelta Optimizer](https://wikidocs.net/157281)
* [러닝 레이트 스케쥴러](https://gaussian37.github.io/dl-pytorch-lr_scheduler/)
