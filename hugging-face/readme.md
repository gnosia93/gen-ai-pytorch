### 허깅페이스 로그인 ###

![](https://github.com/gnosia93/llm_diffusion_pytorch/blob/main/images/hf-login.png)

### GPU 메모리 Overflow ###

![](https://github.com/gnosia93/llm_diffusion_pytorch/blob/main/images/hf-memory-2.png)

### QLora ###

* [Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA](https://huggingface.co/blog/4bit-transformers-bitsandbytes)
