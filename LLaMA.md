* LLaMA explained: KV-Cache, Rotary Positional Embedding, RMS Norm, Grouped Query Attention, SwiGLU
  https://www.youtube.com/watch?v=Mn_9W1nCFLo
